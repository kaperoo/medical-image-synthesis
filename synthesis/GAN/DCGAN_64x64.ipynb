{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1JcrFLP0VyAJ9IBhjWyetUBtEzZO7fmBo","timestamp":1738596830019}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"qoiiKvhfaM6C","executionInfo":{"status":"ok","timestamp":1743424446017,"user_tz":-60,"elapsed":68,"user":{"displayName":"Jam Brierley","userId":"05248307284792592995"}}},"outputs":[],"source":["# Load TensorBoard extension\n","%load_ext tensorboard\n","\n","# Start TensorBoard\n","from datetime import datetime\n","import os\n","\n","# Set up a log directory for TensorBoard\n","log_dir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","os.makedirs(log_dir, exist_ok=True)\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"PEKBoCpTvmnI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743424468853,"user_tz":-60,"elapsed":22769,"user":{"displayName":"Jam Brierley","userId":"05248307284792592995"}},"outputId":"ae8e60d0-6180-4e3e-aa47-6469f1e6be13"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#INPORT DATA AND PREPROCESS"],"metadata":{"id":"dcGgyMD3lPU3"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.stats import zscore\n","import os\n","import cv2\n","from torch.utils.data import DataLoader, random_split\n","import torch.optim as optim\n","import torchvision.utils\n","from torchvision import datasets, transforms\n","import numpy as np\n","def preProcessing():\n","    LABELS_PATH = '/content/drive/My Drive/OCTDL_labels.csv'\n","    INPUT_PATH = '/content/drive/My Drive/OCTDL_AUGMENTED'\n","    OUTPUT_PATH = '/content/drive/My Drive/OCTDL_DCGAN_AUGMENTED'\n","\n","    df = pd.read_csv(LABELS_PATH)\n","\n","    dimensions = pd.DataFrame(df, columns = ['file_name', 'image_width', 'image_hight'])\n","\n","    dimensions['z_width'] = zscore(dimensions['image_width'])\n","    dimensions['z_height'] = zscore(dimensions['image_hight'])\n","\n","    z_threshold = 2.5\n","\n","    filtered_dimensions = dimensions[\n","        (abs(dimensions['z_width']) <= z_threshold) &\n","        (abs(dimensions['z_height']) <= z_threshold)\n","    ].copy()\n","\n","\n","    filtered_dimensions['aspect_ratio'] = filtered_dimensions['image_width'] / filtered_dimensions['image_hight']\n","    avg_aspect_ratio = filtered_dimensions['aspect_ratio'].mean()\n","\n","    # We are using A DCGAN\n","    # This *REQUIRES* 64x64 by default\n","    # there /is/ a way around this (see https://github.com/pytorch/examples/issues/70)\n","    # but this is kind of elaborate and for now will not be implemented.\n","    # TODO: come back and implement it.\n","    # Another alterative would be to go back to SRGAN and upscale the images?\n","    height = 64\n","    width = 64\n","    target_size = (width, height)\n","\n","    def resize_and_save(classname):\n","        input_dir = INPUT_PATH + '/augmented_data/' + classname\n","        output_dir = OUTPUT_PATH + '/' + classname\n","\n","        os.makedirs(output_dir, exist_ok = True)\n","\n","        for _, row in filtered_dimensions.iterrows():\n","                file_name = row['file_name'] + '.jpg'\n","                if classname.lower() not in file_name:\n","                    continue\n","                image_path = os.path.join(input_dir, file_name)\n","\n","                # Read the image\n","                img = cv2.imread(image_path)\n","                if img is None:\n","                    print(f\"Error loading image {file_name}\")\n","                    continue\n","\n","                resized_img = cv2.resize(img, target_size, interpolation = cv2.INTER_AREA)\n","\n","                output_path = os.path.join(output_dir, file_name)\n","                cv2.imwrite(output_path, resized_img)\n","\n","    classnames = ['AMD', 'DME', 'ERM', 'NO', 'RAO', 'RVO', 'VID']\n","\n","    #for classname in classnames:\n","    #    resize_and_save(classname)\n","\n","\n","    # hyperparameters - to be adjusted\n","    # currently 70/30 split\n","    TEST_TRAIN_SPLIT = 0.3\n","    # we'll try 32 for now\n","    BATCH_SIZE = 32\n","\n","    transform = transforms.Compose([\n","        transforms.Grayscale(num_output_channels=1),\n","        transforms.ToTensor()\n","    ])\n","\n","    num_channels = 1 # used later when declaring generator/descriminator\n","    features_discrim = 16\n","    # 64 by 64 images\n","    dataset = datasets.ImageFolder(OUTPUT_PATH, transform=transform)\n","\n","    #full preprocessed images\n","    #dataset = datasets.ImageFolder(INPUT_PATH, transform=transform)\n","\n","    n_test = int(np.floor(TEST_TRAIN_SPLIT * len(dataset)))\n","    n_train = len(dataset) - n_test\n","\n","    train_ds, test_ds = random_split(dataset, [n_train, n_test])\n","\n","    train_dl = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n","    test_dl = DataLoader(test_ds, batch_size = BATCH_SIZE, shuffle = False, num_workers = 4)\n","\n","\n","    # some useful info about the dataset\n","    print(f\"Classes: {dataset.classes}\")\n","    print(f\"Number of training samples: {len(train_ds)}\")\n","    print(f\"Number of testing samples: {len(test_ds)}\")\n","    #for i, (x, label) in enumerate(train_dl):\n","        #print(label)\n","        #break\n","        #print(f\"Image shape: {x.shape}\")\n","    return train_dl, test_dl"],"metadata":{"id":"AMi_bCq0vaHo","executionInfo":{"status":"ok","timestamp":1743424480766,"user_tz":-60,"elapsed":11909,"user":{"displayName":"Jam Brierley","userId":"05248307284792592995"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#Declaring Generator"],"metadata":{"id":"sCiZIxrUlU2H"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","class Generator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Generator, self).__init__()\n","        self.ngpu = ngpu\n","        num_channels = 1\n","        features_gen = 16\n","        self.main = nn.Sequential(\n","\n","            # input is Z, going into a convolution\n","            nn.ConvTranspose2d( 100, features_gen * 8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(features_gen * 8),\n","            nn.ReLU(True),\n","            # state size. ``(features_gen*8) x 4 x 4``\n","            nn.ConvTranspose2d(features_gen * 8, features_gen * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(features_gen * 4),\n","            nn.ReLU(True),\n","            # state size. ``(features_gen*4) x 8 x 8``\n","            nn.ConvTranspose2d( features_gen * 4, features_gen * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(features_gen * 2),\n","            nn.ReLU(True),\n","            # state size. ``(features_gen*2) x 16 x 16``\n","            nn.ConvTranspose2d( features_gen * 2, features_gen, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(features_gen),\n","            nn.ReLU(True),\n","            # state size. ``(features_gen) x 32 x 32``\n","            nn.ConvTranspose2d( features_gen, num_channels, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","            # state size. ``(num_channels) x 64 x 64``\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# Create the generator\n","netG = Generator(1).to(device)\n","\n","# Handle multi-GPU if desired\n","#if (device.type == 'cuda') and (ngpu > 1):\n","#    netG = nn.DataParallel(netG, list(range(ngpu)))\n","\n","\n","def initialize_weights(model):\n","    # Initializes weights according to the DCGAN paper\n","    for m in model.modules():\n","        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n","            nn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n","\n","# Apply the ``weights_init`` function to randomly initialize all weights\n","#  to ``mean=0``, ``stdev=0.02``.\n","netG.apply(initialize_weights)\n","\n","# Print the model\n","print(netG)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ohYa4sW7j7ng","executionInfo":{"status":"ok","timestamp":1743424481291,"user_tz":-60,"elapsed":553,"user":{"displayName":"Jam Brierley","userId":"05248307284792592995"}},"outputId":"bc420ec7-65e1-444b-8fe5-c30d0ccb90d5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Generator(\n","  (main): Sequential(\n","    (0): ConvTranspose2d(100, 128, kernel_size=(4, 4), stride=(1, 1), bias=False)\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU(inplace=True)\n","    (9): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): ReLU(inplace=True)\n","    (12): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (13): Tanh()\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["#Declaring Discriminator"],"metadata":{"id":"etlX-sWXlZCo"}},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Discriminator, self).__init__()\n","        self.ngpu = ngpu\n","        num_channels = 1\n","        features_discrim = 16\n","        self.main = nn.Sequential(\n","            # input is ``(num_channels) x 64 x 64``\n","            nn.Conv2d(num_channels, features_discrim, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. ``(features_discrim) x 32 x 32``\n","            nn.Conv2d(features_discrim, features_discrim * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(features_discrim * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. ``(features_discrim*2) x 16 x 16``\n","            nn.Conv2d(features_discrim * 2, features_discrim * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(features_discrim * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. ``(features_discrim*4) x 8 x 8``\n","            nn.Conv2d(features_discrim * 4, features_discrim * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(features_discrim * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. ``(features_discrim*8) x 4 x 4``\n","            nn.Conv2d(features_discrim * 8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# Create the Discriminator\n","netD = Discriminator(1).to(device)\n","\n","# Handle multi-GPU if desired\n","#if (device.type == 'cuda') and (ngpu > 1):\n","#    netD = nn.DataParallel(netD, list(range(ngpu)))\n","\n","# Apply the ``initialize_weights`` function to randomly initialize all weights\n","# like this: ``to mean=0, stdev=0.2``.\n","netD.apply(initialize_weights)\n","\n","# Print the model\n","print(netD)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G4x2VwSEkAqY","executionInfo":{"status":"ok","timestamp":1743424481338,"user_tz":-60,"elapsed":37,"user":{"displayName":"Jam Brierley","userId":"05248307284792592995"}},"outputId":"cce477c0-c28d-42a8-b026-85638fc187e7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Discriminator(\n","  (main): Sequential(\n","    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (5): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (8): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (11): Conv2d(128, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n","    (12): Sigmoid()\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["#initialise loss function and optimisers"],"metadata":{"id":"XFHDs-jLlcJp"}},{"cell_type":"code","source":["import torch.optim as optim\n","# Initialize the ``BCELoss`` function\n","criterion = nn.BCELoss()\n","\n","# Create batch of latent vectors that we will use to visualize\n","#  the progression of the generator\n","fixed_noise = torch.randn(64, 100, 1, 1, device=device)\n","\n","# Establish convention for real and fake labels during training\n","real_label = 1.\n","fake_label = 0.\n","\n","LEARNING_RATE = 0.0002\n","# Setup Adam optimizers for both G and D\n","optimizerD = optim.Adam(netD.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))"],"metadata":{"id":"N4wJwUEUkrfc","executionInfo":{"status":"ok","timestamp":1743424481357,"user_tz":-60,"elapsed":18,"user":{"displayName":"Jam Brierley","userId":"05248307284792592995"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#Begin Training"],"metadata":{"id":"jsl1Hrsklsei"}},{"cell_type":"code","source":["# Training Loop\n","\n","# Lists to keep track of progress\n","img_list = []\n","G_losses = []\n","D_losses = []\n","iters = 0\n","num_epochs = 200\n","\n","train_d1, test_d1, = preProcessing()\n","dataloader = train_d1\n","\n","print(\"Starting Training Loop...\")\n","# For each epoch\n","for epoch in range(num_epochs):\n","    # For each batch in the dataloader\n","    for i, data in enumerate(train_d1, 0):\n","\n","        ############################\n","        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","        ###########################\n","        ## Train with all-real batch\n","        netD.zero_grad()\n","        # Format batch\n","        real_cpu = data[0].to(device)\n","        b_size = real_cpu.size(0)\n","        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","        # Forward pass real batch through D\n","        output = netD(real_cpu).view(-1)\n","        # Calculate loss on all-real batch\n","        errD_real = criterion(output, label)\n","        # Calculate gradients for D in backward pass\n","        errD_real.backward()\n","        D_x = output.mean().item()\n","\n","        ## Train with all-fake batch\n","        # Generate batch of latent vectors\n","        noise = torch.randn(b_size, 100, 1, 1, device=device)\n","        # Generate fake image batch with G\n","        fake = netG(noise)\n","        label.fill_(fake_label)\n","        # Classify all fake batch with D\n","        output = netD(fake.detach()).view(-1)\n","        # Calculate D's loss on the all-fake batch\n","        errD_fake = criterion(output, label)\n","        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","        errD_fake.backward()\n","        D_G_z1 = output.mean().item()\n","        # Compute error of D as sum over the fake and the real batches\n","        errD = errD_real + errD_fake\n","        # Update D\n","        optimizerD.step()\n","\n","        ############################\n","        # (2) Update G network: maximize log(D(G(z)))\n","        ###########################\n","        netG.zero_grad()\n","        label.fill_(real_label)  # fake labels are real for generator cost\n","        # Since we just updated D, perform another forward pass of all-fake batch through D\n","        output = netD(fake).view(-1)\n","        # Calculate G's loss based on this output\n","        errG = criterion(output, label)\n","        # Calculate gradients for G\n","        errG.backward()\n","        D_G_z2 = output.mean().item()\n","        # Update G\n","        optimizerG.step()\n","\n","        # Output training stats\n","        if i % 50 == 0:\n","            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","                  % (epoch, num_epochs, i, len(dataloader),\n","                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","        # Save Losses for plotting later\n","        G_losses.append(errG.item())\n","        D_losses.append(errD.item())\n","\n","        # Check how the generator is doing by saving G's output on fixed_noise\n","        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n","            with torch.no_grad():\n","                fake = netG(fixed_noise).detach().cpu()\n","            img_list.append(torchvision.utils.make_grid(fake, padding=2, normalize=True))\n","\n","        iters += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lxf_i97nlGME","executionInfo":{"status":"error","timestamp":1743424787954,"user_tz":-60,"elapsed":306587,"user":{"displayName":"Jam Brierley","userId":"05248307284792592995"}},"outputId":"6f9697dc-b084-4ca4-cbd1-4a42f7a2825b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Classes: ['AMD', 'DME', 'ERM', 'NO', 'RAO', 'RVO', 'VID']\n","Number of training samples: 1440\n","Number of testing samples: 616\n","Starting Training Loop...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[0/200][0/45]\tLoss_D: 1.3852\tLoss_G: 0.6934\tD(x): 0.5006\tD(G(z)): 0.5000 / 0.4999\n","[1/200][0/45]\tLoss_D: 0.7146\tLoss_G: 1.1868\tD(x): 0.7098\tD(G(z)): 0.3103 / 0.3052\n","[2/200][0/45]\tLoss_D: 0.2870\tLoss_G: 1.9877\tD(x): 0.8757\tD(G(z)): 0.1429 / 0.1370\n","[3/200][0/45]\tLoss_D: 0.1390\tLoss_G: 2.6587\tD(x): 0.9392\tD(G(z)): 0.0734 / 0.0703\n","[4/200][0/45]\tLoss_D: 0.7916\tLoss_G: 1.5903\tD(x): 0.6921\tD(G(z)): 0.3185 / 0.2244\n","[5/200][0/45]\tLoss_D: 0.7057\tLoss_G: 2.1107\tD(x): 0.7128\tD(G(z)): 0.2908 / 0.1290\n","[6/200][0/45]\tLoss_D: 0.5245\tLoss_G: 1.4012\tD(x): 0.7432\tD(G(z)): 0.1782 / 0.2805\n","[7/200][0/45]\tLoss_D: 0.5081\tLoss_G: 2.4682\tD(x): 0.7543\tD(G(z)): 0.1781 / 0.0896\n","[8/200][0/45]\tLoss_D: 0.4484\tLoss_G: 2.2584\tD(x): 0.8417\tD(G(z)): 0.2240 / 0.1132\n","[9/200][0/45]\tLoss_D: 0.7545\tLoss_G: 2.0238\tD(x): 0.6502\tD(G(z)): 0.2186 / 0.1532\n","[10/200][0/45]\tLoss_D: 0.5215\tLoss_G: 2.5366\tD(x): 0.8122\tD(G(z)): 0.2358 / 0.0891\n","[11/200][0/45]\tLoss_D: 0.3932\tLoss_G: 3.0509\tD(x): 0.9296\tD(G(z)): 0.2626 / 0.0513\n","[12/200][0/45]\tLoss_D: 0.2683\tLoss_G: 2.8841\tD(x): 0.9115\tD(G(z)): 0.1514 / 0.0628\n","[13/200][0/45]\tLoss_D: 0.8142\tLoss_G: 3.8519\tD(x): 0.8821\tD(G(z)): 0.4619 / 0.0254\n","[14/200][0/45]\tLoss_D: 0.3800\tLoss_G: 2.6957\tD(x): 0.8285\tD(G(z)): 0.1597 / 0.0795\n","[15/200][0/45]\tLoss_D: 0.4116\tLoss_G: 2.5922\tD(x): 0.7428\tD(G(z)): 0.0619 / 0.0888\n","[16/200][0/45]\tLoss_D: 0.4140\tLoss_G: 2.9749\tD(x): 0.7965\tD(G(z)): 0.1374 / 0.0617\n","[17/200][0/45]\tLoss_D: 0.8643\tLoss_G: 4.8295\tD(x): 0.9763\tD(G(z)): 0.5359 / 0.0086\n","[18/200][0/45]\tLoss_D: 0.3272\tLoss_G: 2.9606\tD(x): 0.8015\tD(G(z)): 0.0747 / 0.0653\n","[19/200][0/45]\tLoss_D: 0.3799\tLoss_G: 3.5972\tD(x): 0.7302\tD(G(z)): 0.0233 / 0.0317\n","[20/200][0/45]\tLoss_D: 0.4772\tLoss_G: 2.7067\tD(x): 0.6900\tD(G(z)): 0.0637 / 0.0890\n","[21/200][0/45]\tLoss_D: 0.2294\tLoss_G: 2.8510\tD(x): 0.8758\tD(G(z)): 0.0818 / 0.0765\n","[22/200][0/45]\tLoss_D: 0.3261\tLoss_G: 1.7676\tD(x): 0.8326\tD(G(z)): 0.1128 / 0.2072\n","[23/200][0/45]\tLoss_D: 0.1618\tLoss_G: 3.1620\tD(x): 0.9128\tD(G(z)): 0.0630 / 0.0496\n","[24/200][0/45]\tLoss_D: 0.4257\tLoss_G: 4.5249\tD(x): 0.9501\tD(G(z)): 0.2937 / 0.0130\n","[25/200][0/45]\tLoss_D: 0.2234\tLoss_G: 3.5077\tD(x): 0.8795\tD(G(z)): 0.0729 / 0.0467\n","[26/200][0/45]\tLoss_D: 0.6863\tLoss_G: 5.3930\tD(x): 0.9564\tD(G(z)): 0.4499 / 0.0055\n","[27/200][0/45]\tLoss_D: 0.4749\tLoss_G: 3.7034\tD(x): 0.9731\tD(G(z)): 0.3328 / 0.0314\n","[28/200][0/45]\tLoss_D: 0.2935\tLoss_G: 2.8084\tD(x): 0.7958\tD(G(z)): 0.0360 / 0.0706\n","[29/200][0/45]\tLoss_D: 0.2796\tLoss_G: 4.0661\tD(x): 0.7922\tD(G(z)): 0.0216 / 0.0249\n","[30/200][0/45]\tLoss_D: 0.1825\tLoss_G: 3.5974\tD(x): 0.8711\tD(G(z)): 0.0288 / 0.0310\n","[31/200][0/45]\tLoss_D: 0.2302\tLoss_G: 4.3639\tD(x): 0.9788\tD(G(z)): 0.1644 / 0.0195\n","[32/200][0/45]\tLoss_D: 0.3304\tLoss_G: 4.8690\tD(x): 0.7732\tD(G(z)): 0.0338 / 0.0101\n","[33/200][0/45]\tLoss_D: 0.1243\tLoss_G: 3.9680\tD(x): 0.9426\tD(G(z)): 0.0558 / 0.0307\n","[34/200][0/45]\tLoss_D: 0.4361\tLoss_G: 3.8311\tD(x): 0.7283\tD(G(z)): 0.0175 / 0.0271\n","[35/200][0/45]\tLoss_D: 0.1382\tLoss_G: 3.1721\tD(x): 0.9473\tD(G(z)): 0.0638 / 0.0530\n","[36/200][0/45]\tLoss_D: 0.2222\tLoss_G: 3.3779\tD(x): 0.8910\tD(G(z)): 0.0884 / 0.0409\n","[37/200][0/45]\tLoss_D: 0.3605\tLoss_G: 3.2844\tD(x): 0.7552\tD(G(z)): 0.0152 / 0.0524\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7c9b37dbbe20>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1582, in _shutdown_workers\n","    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n","  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 149, in join\n","    res = self._popen.wait(timeout)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n","    if not wait([self.sentinel], timeout):\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 948, in wait\n","    ready = selector.select(timeout)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/selectors.py\", line 415, in select\n","    fd_event_list = self._selector.poll(timeout)\n","                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt: \n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-7-c4eb98f6220a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0merrD_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mD_G_z1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Compute error of D as sum over the fake and the real batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m     def structured_traceback(self, etype, evalue, etb, tb_offset=None,\n\u001b[0m\u001b[1;32m   1121\u001b[0m                              number_of_lines_of_context=5):\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2114\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, exc_tuple)\u001b[0m\n\u001b[1;32m   2057\u001b[0m         \"\"\"\n\u001b[1;32m   2058\u001b[0m         \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_exc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/traceback.py\u001b[0m in \u001b[0;36mformat_exception_only\u001b[0;34m(exc, value)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTracebackException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/traceback.py\u001b[0m in \u001b[0;36mformat_exception_only\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_syntax_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__notes__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnote\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__notes__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mnote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'note'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/abc.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/abc.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["#Plot Results"],"metadata":{"id":"58QRwSQ3lwYI"}},{"cell_type":"markdown","source":["actually save the models you absolute complete and total moron"],"metadata":{"id":"fR-9ogXWhp5I"}},{"cell_type":"code","source":["torch.save(netG.state_dict, '/content/drive/My Drive/OCTDL_DCGAN_AUGMENTED/netG.pth')\n","torch.save(netD.state_dict, '/content/drive/My Drive/OCTDL_DCGAN_AUGMENTED/netD.pth')\n","torch.save(netG, '/content/drive/My Drive/OCTDL_DCGAN_AUGMENTED/netGfull.pth')\n","torch.save(netD, '/content/drive/My Drive/OCTDL_DCGAN_AUGMENTED/netDfull.pth')\n","netG.eval()\n","netD.eval()"],"metadata":{"id":"Z86WAFkqhUoD","executionInfo":{"status":"aborted","timestamp":1743424787959,"user_tz":-60,"elapsed":1,"user":{"displayName":"Jam Brierley","userId":"05248307284792592995"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["example comparison"],"metadata":{"id":"TnHKHeSIhtBf"}},{"cell_type":"code","source":["plt.figure(figsize=(10,5))\n","plt.title(\"Generator and Discriminator Loss During Training\")\n","plt.plot(G_losses,label=\"G\")\n","plt.plot(D_losses,label=\"D\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()\n","\n","# Grab a batch of real images from the dataloader\n","real_batch = next(iter(dataloader))\n","\n","# Plot the real images\n","plt.figure(figsize=(15,15))\n","plt.subplot(1,2,1)\n","plt.axis(\"off\")\n","plt.title(\"Real Images\")\n","plt.imshow(np.transpose(torchvision.utils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n","\n","# Plot the fake images from the last epoch\n","plt.subplot(1,2,2)\n","plt.axis(\"off\")\n","plt.title(\"Fake Images\")\n","plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n","plt.show()"],"metadata":{"id":"aATmVd6NlMgM","executionInfo":{"status":"aborted","timestamp":1743424787984,"user_tz":-60,"elapsed":11,"user":{"displayName":"Jam Brierley","userId":"05248307284792592995"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Alright now we got asked for 2056 example images so we making them"],"metadata":{"id":"1AJr8ZaGh11z"}},{"cell_type":"code","source":["plt.figure(figsize=(10,5))\n","plt.title(\"Generator and Discriminator Loss During Training\")\n","plt.plot(G_losses,label=\"G\")\n","plt.plot(D_losses,label=\"D\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"aV7NAevakaKn","executionInfo":{"status":"aborted","timestamp":1743424787987,"user_tz":-60,"elapsed":1,"user":{"displayName":"Jam Brierley","userId":"05248307284792592995"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NewG = torch.load('/content/drive/My Drive/OCTDL_DCGAN_AUGMENTED/netGfull.pth',weights_only=False)\n","#NewG = Generator(1).to(device)\n","#NewG.load_state_dict(torch.load('/content/drive/My Drive/OCTDL_DCGAN_AUGMENTED/netG.pth', weights_only=False))\n","NewG.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JfWPW4CTk2Ci","executionInfo":{"status":"ok","timestamp":1743424980934,"user_tz":-60,"elapsed":43,"user":{"displayName":"Jam Brierley","userId":"05248307284792592995"}},"outputId":"7df0a98c-d6ab-4cf3-ae4e-1c7779323d6c"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Generator(\n","  (main): Sequential(\n","    (0): ConvTranspose2d(100, 128, kernel_size=(4, 4), stride=(1, 1), bias=False)\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU(inplace=True)\n","    (9): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): ReLU(inplace=True)\n","    (12): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (13): Tanh()\n","  )\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["#noise = torch.randn(1, 100, 1, 1, device=device)\n","#fake = NewG(noise)\n","fake = np.load('/content/drive/My Drive/OCTDL_DCGAN_AUGMENTED/AMD/amd_1047099_1.jpg')\n","plt.figure(figsize=(64,64))\n","plt.imshow(np.transpose(torchvision.utils.make_grid(fake.detach().cpu(), padding=2, normalize=True),(1,2,0)))\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"zU7_kW9fh7Kc","executionInfo":{"status":"error","timestamp":1743425198620,"user_tz":-60,"elapsed":19,"user":{"displayName":"Jam Brierley","userId":"05248307284792592995"}},"outputId":"4402cbd1-0350-4a39-fa51-49a9853c976a"},"execution_count":21,"outputs":[{"output_type":"error","ename":"UnpicklingError","evalue":"Failed to interpret file '/content/drive/My Drive/OCTDL_DCGAN_AUGMENTED/AMD/amd_1047099_1.jpg' as a pickle","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\xff'.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-aa087782d2b7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#noise = torch.randn(1, 100, 1, 1, device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#fake = NewG(noise)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/OCTDL_DCGAN_AUGMENTED/AMD/amd_1047099_1.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    493\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 raise pickle.UnpicklingError(\n\u001b[0m\u001b[1;32m    496\u001b[0m                     f\"Failed to interpret file {file!r} as a pickle\") from e\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: Failed to interpret file '/content/drive/My Drive/OCTDL_DCGAN_AUGMENTED/AMD/amd_1047099_1.jpg' as a pickle"]}]},{"cell_type":"code","source":["for counter in range(2056):\n","  noise = torch.randn(1, 100, 1, 1, device=device)\n","  fake = netG(noise)\n","  torchvision.utils.save_image(fake.detach(), '%s/%d.png' % (\"/content/drive/My Drive/OCTDL_DCGAN_AUGMENTED/ImageGen2056\", counter), normalize=True)\n","#noise = torch.randn(256, 100, 1, 1, device=device)\n","#fake = netG(noise)\n","#torchvision.utils.save_image(fake.detach(), '%s/2.png' % (\"/content/drive/My Drive/OCTDL_DCGAN_AUGMENTED\", epoch), normalize=True)\n","#plt.figure(figsize=(64,64))\n","#plt.imshow(np.transpose(torchvision.utils.make_grid(fake.detach().cpu(), padding=2, normalize=True),(1,2,0)))\n","#plt.show()"],"metadata":{"id":"DQnglIL6q58m","executionInfo":{"status":"aborted","timestamp":1743424788124,"user_tz":-60,"elapsed":342491,"user":{"displayName":"Jam Brierley","userId":"05248307284792592995"}}},"execution_count":null,"outputs":[]}]}